{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS FUNCTIONS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the average word vector for a tweet\n",
    "def get_avg_embedding(tweet, model, vector_size=200):\n",
    "    words = tweet.split()  # Tokenize by whitespace\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:  # If no words in the tweet are in the vocabulary, return a zero vector\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "sym_spell.load_dictionary(\"en-80k.txt\", term_index=0, count_index=1)\n",
    "# Correct word\n",
    "def correct_text(text):\n",
    "    sug = sym_spell.lookup(text, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "    if sug:\n",
    "        return sug[0].term\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "# Basic preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenization\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [correct_text(word) for word in words if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# Calculate sentiment rate of a text\n",
    "def get_sentiment_rate(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return np.abs(scores['compound'])\n",
    "\n",
    "\n",
    "football_words = [\"full time\", \"goal\", \"half time\", \"kick off\", \"owngoal\", \"penalty\", \"match\", \"red card\", \"yellow card\"]\n",
    "# Calculate the number of football words in a tweet\n",
    "def count_football_words(text):\n",
    "    return sum(word in text for word in football_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCCESS PART 0 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESS PART 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hbar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/hbar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESS PART 0 : OK\n"
     ]
    }
   ],
   "source": [
    "print(\"PREPROCESS PART 0...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "os.makedirs(\"tmp/\", exist_ok = True)\n",
    "\n",
    "\n",
    "# Download some NLP models for processing, optional\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load GloVe model with Gensim's API\n",
    "embeddings_model = api.load(\"glove-twitter-200\")  # 200-dimensional GloVe embeddings\n",
    "\n",
    "\n",
    "print(\"PREPROCESS PART 0 : OK\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS PART 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESS PART 1...\n",
      "PREPROCESS PART 1 : OK\n"
     ]
    }
   ],
   "source": [
    "print(\"PREPROCESS PART 1...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "go = False\n",
    "\n",
    "\n",
    "if go or not os.path.isfile(\"tmp/processing1.csv\"):\n",
    "    # Read all training files and concatenate them into one dataframe\n",
    "    li = []\n",
    "    for filename in os.listdir(\"train_tweets\"):\n",
    "        df = pd.read_csv(\"train_tweets/\" + filename)\n",
    "        li.append(df)\n",
    "    df = pd.concat(li, ignore_index=True)\n",
    "\n",
    "    # Apply preprocessing to each tweet\n",
    "    df['Tweet'] = df['Tweet'].apply(preprocess_text)\n",
    "\n",
    "    df.to_csv(\"tmp/processing1.csv\", index=False, encoding=\"utf-8\")\n",
    "else:\n",
    "    df = pd.read_csv(\"tmp/processing1.csv\")\n",
    "\n",
    "\n",
    "print(\"PREPROCESS PART 1 : OK\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS PART 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESS PART 2...\n",
      "PREPROCESS PART 2 : OK\n"
     ]
    }
   ],
   "source": [
    "print(\"PREPROCESS PART 2...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "vector_size = 200  # Adjust based on the chosen GloVe model\n",
    "go = False\n",
    "\n",
    "\n",
    "if go or not os.path.isfile(\"tmp/X.npy\") and not os.path.isfile(\"tmp/y.npy\"):\n",
    "    # Apply preprocessing to each tweet and obtain vectors\n",
    "    tweet_vectors = np.vstack([get_avg_embedding(tweet, embeddings_model, vector_size) for tweet in df['Tweet']])\n",
    "    tweet_df = pd.DataFrame(tweet_vectors)\n",
    "\n",
    "    # Attach the vectors into the original dataframe\n",
    "    period_features = pd.concat([df, tweet_df], axis=1)\n",
    "    period_features = df\n",
    "\n",
    "    ##\n",
    "    ##\n",
    "\n",
    "    # Ajouter une colonne contenant le nombre de tweets par PeriodID\n",
    "    period_features['TweetCount'] = period_features.groupby(['MatchID', 'PeriodID', 'ID'])['Tweet'].transform('size').fillna(0)\n",
    "    period_features['TweetCount'] = period_features['TweetCount'] / period_features['TweetCount'].max()\n",
    "\n",
    "    # Ajouter une colonne contenant le nombre de mots li√©s au foot par tweet\n",
    "    period_features['FootballWordCount'] = period_features['Tweet'].apply(count_football_words).fillna(0)\n",
    "    period_features['FootballWordCount'] = period_features['FootballWordCount'] / period_features['FootballWordCount'].max()\n",
    "\n",
    "    # Ajouter une colonne contenant le score de sentiment\n",
    "    period_features['Sentiment'] = period_features['Tweet'].apply(get_sentiment_rate).fillna(0)\n",
    "\n",
    "    ##\n",
    "    ##\n",
    "\n",
    "    # Drop the columns that are not useful anymore\n",
    "    period_features = period_features.drop(columns=['Timestamp', 'Tweet'])\n",
    "\n",
    "    # Group the tweets into their corresponding periods. This way we generate an average embedding vector for each period\n",
    "    period_features = period_features.groupby(['MatchID', 'PeriodID', 'ID']).mean().reset_index()\n",
    "\n",
    "    # We drop the non-numerical features and keep the embeddings values for each period\n",
    "    X = period_features.drop(columns=['EventType', 'MatchID', 'PeriodID', 'ID']).values\n",
    "    # We extract the labels of our training samples\n",
    "    y = period_features['EventType'].values\n",
    "\n",
    "    np.save(\"tmp/X.npy\", X)\n",
    "    np.save(\"tmp/y.npy\", y)\n",
    "else:\n",
    "    X = np.load(\"tmp/X.npy\")\n",
    "    y = np.load(\"tmp/y.npy\")\n",
    "\n",
    "\n",
    "print(\"PREPROCESS PART 2 : OK\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on a test set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split our data into a training and test set that we can use to train our classifier without fine-tuning into the\n",
    "# validation set and without submitting too many times into Kaggle\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(\"Test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVC(kernel=\"rbf\", random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# clf = SVC(C=0.5, kernel=\"poly\", degree=7, random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(\"Test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.6651090342679128\n",
      "Test set:  0.6573208722741433\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=170, max_depth=10, max_features='sqrt')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.6386292834890965\n",
      "Test set:  0.6137071651090342\n",
      "Test set:  0.6526479750778816\n",
      "Test set:  0.6464174454828661\n",
      "Test set:  0.6573208722741433\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(random_state=42, n_estimators=50)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = XGBClassifier(random_state=42, n_estimators=170, eval_metric=\"logloss\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = XGBClassifier(random_state=42, n_estimators=170, learning_rate=0.1, max_depth=6, subsample=1, eval_metric=\"logloss\", booster=\"gbtree\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = XGBClassifier(random_state=42, n_estimators=195, learning_rate=0.2, max_depth=3, subsample=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)          \n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "clf = XGBClassifier(random_state=42, n_estimators=140, learning_rate=0.2, max_depth=3, subsample=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.6697819314641744\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42, n_estimators=205, max_depth=7, max_features='sqrt')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  0.6682242990654206\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(random_state=42, n_estimators=80, learning_rate=0.05, max_depth=4, subsample=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)          \n",
    "print(\"Test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Evaluation on a test set : M√©thode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Stacking): 0.660436137071651\n"
     ]
    }
   ],
   "source": [
    "# Mod√®les de base\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=170, max_depth=10, max_features='sqrt')\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=170, learning_rate=0.1, max_depth=6, subsample=1, eval_metric=\"logloss\", booster=\"gbtree\")\n",
    "base_models = [ ('rf', rf), ('xgb', xgb) ]\n",
    "\n",
    "# M√©ta-mod√®le\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking\n",
    "stack = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# √âvaluation\n",
    "stack_pred = stack.predict(X_test)\n",
    "print(\"Accuracy (Stacking):\", accuracy_score(y_test, stack_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Stacking): 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Mod√®les de base\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100)\n",
    "base_models = [ ('rf', rf), ('xgb', xgb) ]\n",
    "\n",
    "# M√©ta-mod√®le\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking\n",
    "stack = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# √âvaluation\n",
    "stack_pred = stack.predict(X_test)\n",
    "print(\"Accuracy (Stacking):\", accuracy_score(y_test, stack_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Stacking): 0.6853582554517134\n"
     ]
    }
   ],
   "source": [
    "# Mod√®les de base\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "svc =  SVC(kernel=\"rbf\", random_state=42)\n",
    "base_models = [ ('rf', rf), ('xgb', xgb), ('lr', lr), ('svc', svc) ]\n",
    "\n",
    "# M√©ta-mod√®le\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking\n",
    "stack = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# √âvaluation\n",
    "stack_pred = stack.predict(X_test)\n",
    "print(\"Accuracy (Stacking):\", accuracy_score(y_test, stack_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Stacking): 0.6713395638629284\n"
     ]
    }
   ],
   "source": [
    "# Mod√®les de base\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=205, max_depth=7, max_features='sqrt')\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=80, learning_rate=0.05, max_depth=4, subsample=1)\n",
    "base_models = [ ('rf', rf), ('xgb', xgb) ]\n",
    "\n",
    "# M√©ta-mod√®le\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking\n",
    "stack = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# √âvaluation\n",
    "stack_pred = stack.predict(X_test)\n",
    "print(\"Accuracy (Stacking):\", accuracy_score(y_test, stack_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Stacking): 0.6728971962616822\n"
     ]
    }
   ],
   "source": [
    "# Mod√®les de base\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=205, max_depth=7, max_features='sqrt')\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=80, learning_rate=0.05, max_depth=4, subsample=1)\n",
    "base_models = [ ('rf', rf), ('xgb', xgb) ]\n",
    "\n",
    "# M√©ta-mod√®le\n",
    "meta_model = SVC()\n",
    "\n",
    "# Stacking\n",
    "stack = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# √âvaluation\n",
    "stack_pred = stack.predict(X_test)\n",
    "print(\"Accuracy (Stacking):\", accuracy_score(y_test, stack_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Stacking): 0.67601246105919\n"
     ]
    }
   ],
   "source": [
    "# Mod√®les de base\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=205, max_depth=7, max_features='sqrt')\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=80, learning_rate=0.05, max_depth=4, subsample=1)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "svc =  SVC(kernel=\"rbf\", random_state=42)\n",
    "base_models = [ ('rf', rf), ('xgb', xgb), ('lr', lr), ('svc', svc) ]\n",
    "\n",
    "# M√©ta-mod√®le\n",
    "meta_model = SVC()\n",
    "\n",
    "# Stacking\n",
    "stack = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# √âvaluation\n",
    "stack_pred = stack.predict(X_test)\n",
    "print(\"Accuracy (Stacking):\", accuracy_score(y_test, stack_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6915887850467289\n",
      "0.6962616822429907\n",
      "0.6869158878504673\n",
      "0.6853582554517134\n",
      "0.6791277258566978\n",
      "0.6853582554517134\n",
      "0.6853582554517134\n",
      "0.6869158878504673\n",
      "0.6900311526479751\n",
      "0.6838006230529595\n",
      "0.6931464174454829\n",
      "0.6915887850467289\n",
      "0.6947040498442367\n",
      "0.677570093457944\n",
      "0.6915887850467289\n",
      "0.6838006230529595\n",
      "0.6838006230529595\n",
      "0.6791277258566978\n",
      "0.6853582554517134\n",
      "Accuracy (Stacking): 0.6962616822429907 with cv = 3\n"
     ]
    }
   ],
   "source": [
    "# Mod√®les de base\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "svc =  SVC(kernel=\"rbf\", random_state=42)\n",
    "base_models = [ ('rf', rf), ('xgb', xgb), ('lr', lr), ('svc', svc) ]\n",
    "    \n",
    "# M√©ta-mod√®le\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Find best cv\n",
    "max_score = 0\n",
    "max_cv = 0\n",
    "\n",
    "for i in range(2, 21):\n",
    "    # Stacking\n",
    "    stack = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=i)\n",
    "    stack.fit(X_train, y_train)\n",
    "    \n",
    "    # √âvaluation\n",
    "    stack_pred = stack.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, stack_pred)\n",
    "\n",
    "    print(accuracy)\n",
    "\n",
    "    # Udapte ?\n",
    "    if max_score < accuracy:\n",
    "        max_score = accuracy\n",
    "        max_cv = i\n",
    "\n",
    "# Print result\n",
    "print(\"Accuracy (Stacking):\", max_score, \"with cv =\", max_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Evaluation on a test set : M√©thode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Voting): 0.6526479750778816\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des mod√®les\n",
    "# Mod√®les de base\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf),\n",
    "    ('xgb', xgb),\n",
    "    ('lr', lr)\n",
    "], voting='soft') # 'soft' pour utiliser les probabilit√©s, 'hard' pour le vote majoritaire \n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "voting_pred = voting_clf.predict(X_test)\n",
    "print(\"Accuracy (Voting):\", accuracy_score(y_test, voting_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Evaluation on a test set : M√©thode 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Weighted Average): 0.6573208722741433\n"
     ]
    }
   ],
   "source": [
    "# Pred des mod√®les\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=100)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Poids pour les mod√®les\n",
    "weight_rf = 0.3\n",
    "weight_xgb = 0.3\n",
    "weight_lr = 0.4\n",
    "\n",
    "# Moyenne pond√©r√©e des pr√©dictions\n",
    "ensemble_pred_weighted = (weight_rf * rf_pred + weight_xgb * xgb_pred + weight_lr * lr_pred)\n",
    "final_pred_weighted = (ensemble_pred_weighted >= 0.5).astype(int)\n",
    "\n",
    "# √âvaluation\n",
    "print(\"Accuracy (Weighted Average):\", accuracy_score(y_test, final_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Evaluation on a test set : M√©thode 4 (r√©seau de neurones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5580 - loss: 0.6777  \n",
      "Epoch 2/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6136 - loss: 0.6590\n",
      "Epoch 3/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6525 - loss: 0.6358\n",
      "Epoch 4/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6349 - loss: 0.6394\n",
      "Epoch 5/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6311 - loss: 0.6426\n",
      "Epoch 6/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6719 - loss: 0.6247\n",
      "Epoch 7/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6292 - loss: 0.6472\n",
      "Epoch 8/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6509 - loss: 0.6391\n",
      "Epoch 9/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6388 - loss: 0.6392\n",
      "Epoch 10/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6409 - loss: 0.6403\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Accuracy (M√©ta-mod√®le - R√©seau de neurones) : 0.661993769470405\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des mod√®les de base\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Placeholder pour les pr√©dictions issues de la validation crois√©e\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_meta = np.zeros((X_train.shape[0], 3))  # Une colonne par mod√®le\n",
    "test_meta = np.zeros((X_test.shape[0], 3))    # Une colonne par mod√®le\n",
    "\n",
    "# Validation crois√©e pour les mod√®les de base\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Random Forest\n",
    "    rf.fit(X_train_fold, y_train_fold)\n",
    "    train_meta[val_idx, 0] = rf.predict_proba(X_val_fold)[:, 1]\n",
    "    test_meta[:, 0] += rf.predict_proba(X_test)[:, 1] / kf.n_splits\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb.fit(X_train_fold, y_train_fold)\n",
    "    train_meta[val_idx, 1] = xgb.predict_proba(X_val_fold)[:, 1]\n",
    "    test_meta[:, 1] += xgb.predict_proba(X_test)[:, 1] / kf.n_splits\n",
    "\n",
    "    # LogisticRegression\n",
    "    lr.fit(X_train_fold, y_train_fold)\n",
    "    train_meta[val_idx, 2] = lr.predict_proba(X_val_fold)[:, 1]\n",
    "    test_meta[:, 2] += lr.predict_proba(X_test)[:, 1] / kf.n_splits\n",
    "\n",
    "\n",
    "\n",
    "# Construction du m√©ta-mod√®le (r√©seau de neurones)\n",
    "meta_model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=train_meta.shape[1]),  # Couche cach√©e\n",
    "    Dense(32, activation='relu'),                               # Couche cach√©e\n",
    "    Dense(1, activation='sigmoid')                              # Couche de sortie (binaire)\n",
    "])\n",
    "\n",
    "# Compilation du r√©seau de neurones\n",
    "meta_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entra√Ænement\n",
    "meta_model.fit(train_meta, y_train, epochs=10, batch_size=16, verbose=1)\n",
    "\n",
    "# Pr√©dictions sur le jeu de test\n",
    "final_pred = (meta_model.predict(test_meta) > 0.5).astype(int)\n",
    "\n",
    "# √âvaluation\n",
    "print(\"Accuracy (M√©ta-mod√®le - R√©seau de neurones) :\", accuracy_score(y_test, final_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Evaluation on a test set : M√©thode 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 811, number of negative: 684\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 605\n",
      "[LightGBM] [Info] Number of data points in the train set: 1495, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.542475 -> initscore=0.170310\n",
      "[LightGBM] [Info] Start training from score 0.170310\n",
      "Accuracy (M√©ta-mod√®le - LightGBM): 0.6292834890965732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar/miniconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des mod√®les de base\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Placeholder pour les pr√©dictions issues de la validation crois√©e\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_meta = np.zeros((X_train.shape[0], 3))  # Une colonne par mod√®le de base\n",
    "test_meta = np.zeros((X_test.shape[0], 3))    # Une colonne par mod√®le de base\n",
    "\n",
    "# Validation crois√©e pour les mod√®les de base\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Random Forest\n",
    "    rf.fit(X_train_fold, y_train_fold)\n",
    "    train_meta[val_idx, 0] = rf.predict_proba(X_val_fold)[:, 1]\n",
    "    test_meta[:, 0] += rf.predict_proba(X_test)[:, 1] / kf.n_splits\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb.fit(X_train_fold, y_train_fold)\n",
    "    train_meta[val_idx, 1] = xgb.predict_proba(X_val_fold)[:, 1]\n",
    "    test_meta[:, 1] += xgb.predict_proba(X_test)[:, 1] / kf.n_splits\n",
    "\n",
    "    # Logistic\n",
    "    lr.fit(X_train, y_train)\n",
    "    train_meta[:, 2] = lr.predict_proba(X_train)[:, 1]\n",
    "    test_meta[:, 2] = lr.predict_proba(X_test)[:, 1] / kf.n_splits\n",
    "\n",
    "\n",
    "\n",
    "# Cr√©ation du Dataset LightGBM\n",
    "lgb_train = lgb.Dataset(train_meta, label=y_train)\n",
    "\n",
    "# Param√®tres de LightGBM\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "# Entra√Ænement du m√©ta-mod√®le\n",
    "meta_model = lgb.train(lgb_params, lgb_train, num_boost_round=100)\n",
    "\n",
    "# Pr√©dictions sur le jeu de test\n",
    "final_pred = (meta_model.predict(test_meta) > 0.5).astype(int)\n",
    "\n",
    "# √âvaluation\n",
    "print(\"Accuracy (M√©ta-mod√®le - LightGBM):\", accuracy_score(y_test, final_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Kaggle submission :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGGLE...\n",
      "KAGGLE : OK\n"
     ]
    }
   ],
   "source": [
    "print(\"KAGGLE...\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "# This time we train our classifier on the full dataset that it is available to us.\n",
    "\n",
    "clf = XGBClassifier(random_state=42, n_estimators=170, learning_rate=0.1, max_depth=6, subsample=1, eval_metric=\"logloss\", booster=\"gbtree\")\n",
    "clf.fit(X, y)\n",
    "predictions = []\n",
    "\n",
    "\n",
    "# We read each file separately, we preprocess the tweets and then use the classifier to predict the labels.\n",
    "# Finally, we concatenate all predictions into a list that will eventually be concatenated and exported\n",
    "# to be submitted on Kaggle.\n",
    "for fname in os.listdir(\"eval_tweets\"):\n",
    "    val_df = pd.read_csv(\"eval_tweets/\" + fname)\n",
    "    val_df['Tweet'] = val_df['Tweet'].apply(preprocess_text)\n",
    "\n",
    "    tweet_vectors = np.vstack([get_avg_embedding(tweet, embeddings_model, vector_size) for tweet in val_df['Tweet']])\n",
    "    tweet_df = pd.DataFrame(tweet_vectors)\n",
    "\n",
    "    period_features = pd.concat([val_df, tweet_df], axis=1)\n",
    "    period_features = val_df\n",
    "\n",
    "    ###\n",
    "    period_features['TweetCount'] = period_features.groupby(['MatchID', 'PeriodID', 'ID'])['Tweet'].transform('size').fillna(0)\n",
    "    period_features['TweetCount'] = period_features['TweetCount'] / period_features['TweetCount'].max()\n",
    "\n",
    "    period_features['FootballWordCount'] = period_features['Tweet'].apply(count_football_words).fillna(0)\n",
    "    period_features['FootballWordCount'] = period_features['FootballWordCount'] / period_features['FootballWordCount'].max()\n",
    "\n",
    "    period_features['Sentiment'] = period_features['Tweet'].apply(get_sentiment_rate).fillna(0)\n",
    "    ###\n",
    "\n",
    "    period_features = period_features.drop(columns=['Timestamp', 'Tweet'])\n",
    "    period_features = period_features.groupby(['MatchID', 'PeriodID', 'ID']).mean().reset_index()\n",
    "    X_pred = period_features.drop(columns=['MatchID', 'PeriodID', 'ID']).values\n",
    "\n",
    "    preds = clf.predict(X_pred)\n",
    "    period_features['EventType'] = preds\n",
    "    predictions.append(period_features[['ID', 'EventType']])\n",
    "\n",
    "pred_df = pd.concat(predictions)\n",
    "pred_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"KAGGLE : OK\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
